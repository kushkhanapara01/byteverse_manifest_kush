version: 0.0.13
timeout: 8
jobId: "245"
jobName: ReadCSVPySpark_Vishnu copy copy
jobType: DataSets
alias: StateManagementCSVVVVV
discoveryPort:
  name: ReadCSVPySpark_Vishnu copy copy
inputPorts:
  - alias: Delimited_1
    isDynamic: true
    path: s3://byte-etl-externaldemo/weather_data/20230626103841.csv
    optional:
      persistDataFrame: false
      jsonSchema: '{"sd":"1"}'
      enableDataReconciliation: false
      enforceSchema: false
      dataSetUrn: ""
      dataProductUrn: ""
    type: inputDelimited
productState:
  persistDataFrame: false
  enableDataReconciliation: false
  enforceSchema: false
  stepName: StateManagementCSV
  path: s3://byte-etl-externaldemo/custom_pyspark_output/weather_data_daily_test.csv
  type: inputDelimited
  isStateManagement: true
  sequence: 3
  alias: StateManagementCSV
  refreshInterval: None
  retentionVersions: ""
  logicalSchema:
    properties:
      City:
        type: STRING
        description: abcadasda
        sourceColumn: abc1
        sourceTable: table1
      Region:
        type: STRING
        description: ""
        sourceColumn: abc2
        sourceTable: table2
  enforceSchemaMethod: ""
  isProfilingEnabled: false
transformation:
  - alias: EMR_PySpark_1
    arguments:
      - s3://byte-etl-externaldemo/weather_data/20230626103841.csv
    pythonFilePath: s3://bp-spark-sql-library-test-acc/custom-jobs/CustomPythonJobWriteParquetTimeOut.py
    optional:
      pythonEnvTarGZPath: s3://byte-etl-externaldemo/pyspark_serverless_test/pyspark_venv.tar.gz
    type: customPySparkEMRServerless
    sequence: 2
    references:
      - alias: Delimited_1
        sqlReference: ""
controlPort:
  dataQualityRules: {}
outputPort:
  subscriptionChannels:
    - channelType: Postgres
      queryType: SQL
